use convolutions_rs::{transposed_convolutions::TransposedConvolutionLayer, Padding};
use ndarray::{Array, Array3, Array4, Dimension};
use ndarray_npy::read_npy;

fn arr_allclose<D: Dimension>(current: &Array<f32, D>, target: &Array<f32, D>) -> bool {
    assert_eq!(
        current.shape(),
        target.shape(),
        "\ngiven array had shape {:?}, but target had shape {:?}",
        current.shape(),
        target.shape()
    );
    (current - target).map(|x| (*x as f32).abs()).sum() < 1e-2
}

fn arr_allclose_64<D: Dimension>(current: &Array<f64, D>, target: &Array<f64, D>) -> bool {
    assert_eq!(
        current.shape(),
        target.shape(),
        "\ngiven array had shape {:?}, but target had shape {:?}",
        current.shape(),
        target.shape()
    );
    (current - target).map(|x| (*x as f64).abs()).sum() < 1e-3
}

// This is an example we saw in live:
// The for same padding, there sometimes isn't a valid way to actually pad the input to get
// the same shape back, so we have to do a cut-off of a type. We'll have to find out how tf actually
// does this
#[test]
fn test_problematic_shape_1() {
    // Testing the example we saw in tensorflow
    let kernel: Array4<f32> = read_npy("tests/npy_files/kernel.npy").unwrap();
    let output: Array3<f32> = read_npy("tests/npy_files/output.npy").unwrap();
    let input: Array3<f32> = read_npy("tests/npy_files/y_hat.npy").unwrap();
    let layer = TransposedConvolutionLayer::new_tf(kernel, 2, Padding::Same);
    let our_output = layer.transposed_convolve(&input);
    // generated via
    // np.save("output.npy", tf_to_pt((tf.nn.conv2d_transpose(y_hat_tf, weight, out1_tf.shape, strides
    // ...: =2, padding="SAME").numpy())))
    //
    // while tf_to_pt is just np.squeeze + np.moveaxis(2,0)
    // and the tf versions are generated by adding an axis and np.moveaxis(1,3)
    assert!(
        arr_allclose(&output, &our_output),
        "{:?} and {:?} not identical",
        output,
        our_output
    );
}

// same shape as in the shape_1_test, but different random values
#[test]
fn test_problematic_shape_1_random() {
    let kernel: Array4<f64> = read_npy("tests/npy_files/kernel_rand_same_shape.npy").unwrap();
    let output: Array3<f64> = read_npy("tests/npy_files/output_rand_same_shape.npy").unwrap();
    let input: Array3<f64> = read_npy("tests/npy_files/input_rand_same_shape.npy").unwrap();
    let layer = TransposedConvolutionLayer::new_tf(kernel, 2, Padding::Same);
    let our_output = layer.transposed_convolve(&input);
    assert!(
        arr_allclose_64(&output, &our_output),
        "{:?} and {:?} not identical",
        output,
        our_output
    );
}

// We have been
#[test]
fn test_problematic_shape_2() {
    let kernel: Array4<f64> = read_npy("tests/npy_files/simple_weight.npy").unwrap();
    let output: Array3<f64> = read_npy("tests/npy_files/output_simple_example.npy").unwrap();
    let input: Array3<f64> = read_npy("tests/npy_files/simple_example_input.npy").unwrap();
    let layer = TransposedConvolutionLayer::new_tf(kernel, 2, Padding::Same);
    let our_output = layer.transposed_convolve(&input);
    assert!(
        arr_allclose_64(&output, &our_output),
        "{:?} and {:?} not identical",
        output,
        our_output
    );
}

#[test]
// Values hand generated like in the above tests, but with "nicer" shapes
fn test_sanity_2() {
    // shapes that we have already known to work from the conv2d_transpose_stride2 test
    let kernel: Array4<f64> = read_npy("tests/npy_files/weight1.npy").unwrap();
    let output: Array3<f64> = read_npy("tests/npy_files/out1.npy").unwrap();
    let input: Array3<f64> = read_npy("tests/npy_files/x1.npy").unwrap();
    let layer = TransposedConvolutionLayer::new_tf(kernel, 2, Padding::Same);
    let our_output = layer.transposed_convolve(&input);
    assert!(
        arr_allclose_64(&output, &our_output),
        "{:?} and {:?} not identical",
        output,
        our_output
    );
}
